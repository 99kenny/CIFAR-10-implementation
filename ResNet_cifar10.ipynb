{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DX1V5mH9nTX2caL0S5bonQNcQveA5a6L",
      "authorship_tag": "ABX9TyNVHUOVAk3Y9dtEYsDxELGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/99kenny/VGGNet-for-cifar-10/blob/main/ResNet_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wujwyCzsZJh5",
        "outputId": "299b69f4-17da-4418-de1d-d25ddd43deef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, ReLU, GlobalAveragePooling2D, Add\n",
        "from keras.models import Model\n",
        "from keras import optimizers, regularizers, utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "Ba_uKWheaah5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download data\n",
        "cifar10 = tf.keras.datasets.cifar10 \n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog','frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "HN0ce5ItdWeT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(train_images,axis=(0,1,2,3))\n",
        "std = np.std(train_images, axis=(0, 1, 2, 3))\n",
        "train_images = (train_images - mean)/(std+1e-7)\n",
        "test_images = (test_images - mean)/(std+1e-7)\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=False,\n",
        "            )  # randomly flip images\n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "metadata": {
        "id": "pE_1M4ZCdY5I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = [1e-4]\n",
        "wd = 1e-4\n",
        "dropout = 0\n",
        "lr = 1e-3\n",
        "batch_size = 256\n",
        "hists = []"
      ],
      "metadata": {
        "id": "GRsILTrsw4ft"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 9 # 56 layers\n",
        "channels = [16, 32, 64]\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "def resNet():\n",
        "  x = Conv2D(channels[0], kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(wd))(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(tf.nn.relu)(x)\n",
        "\n",
        "  for c in channels:\n",
        "      for i in range(n):\n",
        "          subsampling = (i == 0 and c > 16)\n",
        "          strides = (2, 2) if subsampling else (1, 1)\n",
        "          y = Conv2D(c, kernel_size=(3, 3), padding=\"same\", strides=strides, kernel_initializer=\"he_normal\", kernel_regularizer=l2(wd))(x)\n",
        "          y = BatchNormalization()(y)\n",
        "          y = Activation(tf.nn.relu)(y)\n",
        "          y = Conv2D(c, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(wd))(y)\n",
        "          y = BatchNormalization()(y)    \n",
        "          y = Dropout(dropout)(y)    \n",
        "          if subsampling:\n",
        "              x = Conv2D(c, kernel_size=(1, 1), strides=(2, 2), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(wd))(x)\n",
        "          x = Add()([x, y])\n",
        "          x = Activation(tf.nn.relu)(x)\n",
        "\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  outputs = Dense(10, activation=tf.nn.softmax, kernel_initializer=\"he_normal\")(x)\n",
        "  return Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "K2zuRMERdr8k"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_size in [128,256]:\n",
        "  model = resNet()\n",
        "  model.compile(optimizer='Adam', \n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "  learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                              patience=10, \n",
        "                                              verbose=1, \n",
        "                                              factor=0.1, \n",
        "                                              min_lr=0.000000001)\n",
        "\n",
        "  hists.append(model.fit(datagen.flow(train_images, train_labels, batch_size=256), epochs=50,\n",
        "              validation_data=(test_images, test_labels),callbacks = [learning_rate_reduction]))"
      ],
      "metadata": {
        "id": "7aNWoDI3ZWxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4becdeaf-e9dc-4c1c-9919-33217cac1128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "196/196 [==============================] - 66s 142ms/step - loss: 2.2275 - accuracy: 0.3773 - val_loss: 3.0776 - val_accuracy: 0.2570 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "196/196 [==============================] - 27s 135ms/step - loss: 1.6760 - accuracy: 0.5367 - val_loss: 2.8689 - val_accuracy: 0.3648 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 1.4489 - accuracy: 0.6167 - val_loss: 1.7303 - val_accuracy: 0.5674 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 1.2827 - accuracy: 0.6763 - val_loss: 1.4767 - val_accuracy: 0.6241 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "196/196 [==============================] - 26s 132ms/step - loss: 1.1712 - accuracy: 0.7095 - val_loss: 1.4830 - val_accuracy: 0.6356 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 1.0790 - accuracy: 0.7401 - val_loss: 1.5333 - val_accuracy: 0.6174 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 1.0125 - accuracy: 0.7578 - val_loss: 1.2484 - val_accuracy: 0.7003 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "196/196 [==============================] - 27s 135ms/step - loss: 0.9599 - accuracy: 0.7722 - val_loss: 1.8352 - val_accuracy: 0.5907 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.9123 - accuracy: 0.7868 - val_loss: 1.0758 - val_accuracy: 0.7370 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.8747 - accuracy: 0.7976 - val_loss: 1.2189 - val_accuracy: 0.6964 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.8420 - accuracy: 0.8074 - val_loss: 1.0267 - val_accuracy: 0.7601 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "196/196 [==============================] - 26s 133ms/step - loss: 0.8092 - accuracy: 0.8150 - val_loss: 1.1212 - val_accuracy: 0.7198 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.7892 - accuracy: 0.8176 - val_loss: 1.0605 - val_accuracy: 0.7405 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "196/196 [==============================] - 27s 136ms/step - loss: 0.7536 - accuracy: 0.8306 - val_loss: 0.9962 - val_accuracy: 0.7661 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.7410 - accuracy: 0.8323 - val_loss: 0.8803 - val_accuracy: 0.7893 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.7158 - accuracy: 0.8395 - val_loss: 1.2117 - val_accuracy: 0.7263 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.7003 - accuracy: 0.8426 - val_loss: 1.0189 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "196/196 [==============================] - 27s 135ms/step - loss: 0.6799 - accuracy: 0.8479 - val_loss: 1.0346 - val_accuracy: 0.7566 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "196/196 [==============================] - 27s 135ms/step - loss: 0.6694 - accuracy: 0.8526 - val_loss: 0.8978 - val_accuracy: 0.7787 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "196/196 [==============================] - 26s 133ms/step - loss: 0.6503 - accuracy: 0.8568 - val_loss: 1.3778 - val_accuracy: 0.6839 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.6423 - accuracy: 0.8566 - val_loss: 0.9102 - val_accuracy: 0.7846 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.6267 - accuracy: 0.8628 - val_loss: 0.9136 - val_accuracy: 0.7880 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.6148 - accuracy: 0.8663 - val_loss: 0.9816 - val_accuracy: 0.7540 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.6057 - accuracy: 0.8679 - val_loss: 0.9374 - val_accuracy: 0.7795 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.5930 - accuracy: 0.8720 - val_loss: 0.7992 - val_accuracy: 0.8043 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "196/196 [==============================] - 27s 135ms/step - loss: 0.5788 - accuracy: 0.8760 - val_loss: 1.0801 - val_accuracy: 0.7484 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.5730 - accuracy: 0.8774 - val_loss: 0.7169 - val_accuracy: 0.8305 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "182/196 [==========================>...] - ETA: 1s - loss: 0.5644 - accuracy: 0.8802"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for hist in hists:\n",
        "  fig, acc_ax = plt.subplots()\n",
        "\n",
        "\n",
        "  acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "  acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "  acc_ax.set_ylabel('accuracy')\n",
        "  acc_ax.legend(loc='upper left')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  outputs = model.predict(test_images)\n",
        "\n",
        "  e1 = tf.keras.metrics.categorical_accuracy(\n",
        "      test_labels, outputs\n",
        "  )\n",
        "\n",
        "  e2 = tf.keras.metrics.top_k_categorical_accuracy(\n",
        "      test_labels, outputs, k=5\n",
        "  )\n",
        "\n",
        "  print(\"top-1 error: \", (np.count_nonzero(e1 == 0) / 10000))\n",
        "  print(\"top-5 error: \", (np.count_nonzero(e2 == 0) / 10000))"
      ],
      "metadata": {
        "id": "L1qYoV9Xv-vq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}